import os
import argparse
import json
from utils import load_and_merge_batches, log_message, select_n_samples

from datasets import Dataset, concatenate_datasets
from transformers import AutoModelForAudioClassification, AutoFeatureExtractor
import evaluate

def main(data_dir, model_name, mapping_json, output_dir):

    # If the output folder does not exist, create it
    if not os.path.exists(output_dir):
        os.makedirs(f"{output_dir}")

    # Load dataset by merging the batches
    dataset = load_and_merge_batches(data_dir)
    
    # FOR TESTING!!! Work only on a balanced subset of the dataset
    #dataset = select_n_samples(dataset, 50)

    num_classes = len(set(dataset["label"]))
    log_message(f"Number of classes in the dataset: {num_classes}")

    # Load label2id and viceversa dictionaries
    with open(mapping_json, "r") as json_file:
        mappings = json.load(json_file)
    id2label = mapping_json['id2label']
    label2id = mapping_json['label2id']
    del mapping_json

    # Load model and feature extractor from the hugging face hub
    model = AutoModelForAudioClassification.from_pretrained(model_name, num_labels=num_classes)
    feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)

    # TO DO!!! Load performance metrics (accuracy, f1 etc...) and evaluate the model, also confusion matrix

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_dir", default="processed_data", help="Directory containing processed data batches")
    parser.add_argument("--mapping_json", default="processed_data/label_mappings.json", help="File containing the mapping from label2id and viceversa ")
    parser.add_argument("--model_dir", default="./finetuned_model", help="Directory of the model to evaluate")
    parser.add_argument("--output_dir", default="./validation_results", help="Directory to save the results of the analysis")
    
    args = parser.parse_args()
    main(args.data_dir, args.model_name, args.output_dir)