{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreisMarco/02456_G128_bird_classification/blob/main/scripts/06_Audio_classification_with_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9f-FLXXbpSd"
      },
      "source": [
        "# 1. Set up environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LAJw6egX4rhI"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYDdhe_hbtkN"
      },
      "source": [
        "## 1.1 Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8a0qjOlnb-wL"
      },
      "outputs": [],
      "source": [
        "# setting up Drive and path for data loading and saving\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# for data processing\n",
        "import numpy as np\n",
        "import re\n",
        "from datasets import Dataset, concatenate_datasets\n",
        "from transformers import AutoFeatureExtractor\n",
        "\n",
        "# for model training and evaluation\n",
        "import torch\n",
        "from torch import nn\n",
        "import evaluate\n",
        "from torch.utils.data import DataLoader\n",
        "from datetime import datetime\n",
        "\n",
        "# for visualisation\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W60ydnPzyuK",
        "outputId": "57170125-8d41-443b-adf7-378f921f3af5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ROUYHgs629nP"
      },
      "outputs": [],
      "source": [
        "# enforcing reproducibility - from NLP - lab 2 notebook\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def enforce_reproducibility(seed=42):\n",
        "    # Sets seed manually for both CPU and CUDA\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    # For atomic operations there is currently\n",
        "    # no simple way to enforce determinism, as\n",
        "    # the order of parallel operations is not known.\n",
        "    # CUDNN\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # System based\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4K03zMywjOhR"
      },
      "outputs": [],
      "source": [
        "enforce_reproducibility()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIjtS5eHbv2_"
      },
      "source": [
        "## 1.2 Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxnBNBYLhCcz",
        "outputId": "b0da7fba-8a37-4897-c253-178b71b37ea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount Drive and set path\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Deep Learning - DTU 2024/project'\n",
        "os.chdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rlmgqFc1fNwM"
      },
      "outputs": [],
      "source": [
        "# load (one batch of) preprocessed data\n",
        "# batch_path = 'batch_1'\n",
        "# dataset = Dataset.load_from_disk(batch_path).remove_columns('__index_level_0__')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4xeyeJmQkBn3"
      },
      "outputs": [],
      "source": [
        "# from Marco's code\n",
        "\n",
        "def sort_numerically(batch_paths):\n",
        "    '''\n",
        "    Necessary for standardizing the batches import order\n",
        "    '''\n",
        "    def extract_number(batch_dir):\n",
        "        match = re.search(r'(\\d+)', batch_dir)\n",
        "        return int(match.group(1)) if match else 0\n",
        "    sorted_paths = sorted(batch_paths, key=extract_number)\n",
        "    return sorted_paths\n",
        "\n",
        "def load_and_merge_batches(batch_folder):\n",
        "    '''\n",
        "    Loads all .arrow files and merges them in a single dataset\n",
        "    '''\n",
        "    print(f\"Loading and merging batches from folder: {batch_folder}\")\n",
        "    batch_paths = [f for f in os.listdir(batch_folder) if os.path.isdir(os.path.join(batch_folder, f))]\n",
        "    batch_paths = sort_numerically(batch_paths)\n",
        "    datasets_list = []\n",
        "\n",
        "    for batch_dir in batch_paths:\n",
        "        batch_path = os.path.join(batch_folder, batch_dir)\n",
        "        dataset = Dataset.load_from_disk(batch_path)\n",
        "        datasets_list.append(dataset)\n",
        "\n",
        "    merged_dataset = concatenate_datasets(datasets_list)\n",
        "    print(f\"Merged {len(datasets_list)} batches into a single dataset.\")\n",
        "    return merged_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNoM8RHz94x-",
        "outputId": "ccb2b298-b6cf-4e89-b598-adb4fcea8102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and merging batches from folder: processed_data\n",
            "Merged 15 batches into a single dataset.\n"
          ]
        }
      ],
      "source": [
        "dataset = load_and_merge_batches(\"processed_data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujUq-Thh08fG",
        "outputId": "f466315d-4b3f-40ca-8bb4-24cc6736e618"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['audio', 'label'],\n",
              "    num_rows: 24496\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# inspect structure\n",
        "dataset = dataset.remove_columns('__index_level_0__')\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMGn4r7zCo8F",
        "outputId": "02c3fc7e-222b-4841-b4d0-c0b2edfbb25d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['audio', 'label'])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "dataset[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdTxGAbpAUH2",
        "outputId": "97da1f57-12e3-4fee-80ea-a8a482587169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49}\n",
            "Number of classes in the dataset: 50\n"
          ]
        }
      ],
      "source": [
        "print(set(dataset['label']))\n",
        "num_classes = len(set(dataset['label']))\n",
        "print(f\"Number of classes in the dataset: {num_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgoZbdX3Wztn",
        "outputId": "838b84fc-b791-4b5c-f6e0-fa32dd222fd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Renamed classes: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
            " 48 49]\n"
          ]
        }
      ],
      "source": [
        "# re-assign classes - takes 3 min\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(dataset[\"label\"])  # Fit on all labels in training set\n",
        "\n",
        "def remap_labels(batch, label_column='label'):\n",
        "    batch[label_column] = label_encoder.transform(batch[label_column])\n",
        "    return batch\n",
        "\n",
        "dataset = dataset.map(remap_labels, batched=True)\n",
        "all_classes = np.unique(dataset['label'])\n",
        "print(f\"Renamed classes: {all_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVtW2mpyAcBW"
      },
      "source": [
        "### 1.2.1 Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guAsdpSUyoOX",
        "outputId": "b768e72f-ce15-451a-9abe-e9d9bd110a48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_dir = 'facebook/wav2vec2-base-960h'\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ja3d46_rvDvL"
      },
      "outputs": [],
      "source": [
        "# extract features - from Marco's code - takes 15 min\n",
        "# def preprocess_function(example):\n",
        "#     inputs = feature_extractor(example['audio'], sampling_rate=16000, padding=True)\n",
        "#     return inputs\n",
        "# dataset = dataset.map(preprocess_function, remove_columns=\"audio\", batched=True, batch_size=32)\n",
        "# print(\"Preprocessed dataset with feature extractor.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QZhyyG_zfu5i"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Compute class weights\n",
        "all_classes = np.unique(dataset['label'])  # Assuming 'label' is your target column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljR-90TiAtDh"
      },
      "source": [
        "### 1.2.2 Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3BfD0nTufmE",
        "outputId": "9551d44d-098f-4757-a0bf-92344867402e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split dataset into training and testing.\n"
          ]
        }
      ],
      "source": [
        "# split dataset into train, val and test - from Marco's code\n",
        "dataset = dataset.train_test_split(test_size=0.1, shuffle=True, stratify_by_column=\"label\", seed=42)\n",
        "print(\"Split dataset into training and testing.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY6LLRisAz86"
      },
      "source": [
        "### 1.2.3 Compute class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "v3pY3Ij_gFit"
      },
      "outputs": [],
      "source": [
        "class_weights = compute_class_weight('balanced', classes=all_classes, y=dataset['train']['label'])\n",
        "\n",
        "# Handle missing classes\n",
        "all_class_weights = {}\n",
        "for class_id in all_classes:\n",
        "  if class_id in class_weights:\n",
        "      all_class_weights[class_id] = class_weights[class_id]\n",
        "  else:\n",
        "      all_class_weights[class_id] = 1.0  # or any default weight you prefer\n",
        "# Convert to Tensor\n",
        "class_weight_tensor = torch.tensor(list(all_class_weights.values()), dtype=torch.float32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8ZIyHn2gqFO",
        "outputId": "5271a4f1-bba9-4235-9e9a-50caa62470fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "all_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFtUHQKwgiEw",
        "outputId": "9cf69ca8-e93d-4857-876f-6e4a4b4a81df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed class weights: [1.48959459 2.0412963  2.84464516 1.3122619  0.52995192 1.29302053\n",
            " 1.60919708 2.19363184 0.71461912 0.41130597 2.18277228 0.36289712\n",
            " 0.62014065 1.33208459 0.65418398 1.32011976 1.02539535 1.3608642\n",
            " 1.48457912 1.91704348 0.7511414  0.85284333 0.86454902 0.89074747\n",
            " 1.59753623 1.8144856  0.44313568 2.19363184 0.60152797 1.67015152\n",
            " 1.26701149 0.41400939 1.76368    1.09955112 1.43155844 1.4177492\n",
            " 1.79967347 1.74968254 0.85284333 1.55253521 1.38219436 1.71564202\n",
            " 0.85119691 0.54977556 0.58245707 2.51954286 0.83984762 2.15082927\n",
            " 3.47181102 0.93613588]\n",
            "Class weights tensor moved to device: cuda\n"
          ]
        }
      ],
      "source": [
        "print(f\"Computed class weights: {class_weights}\")\n",
        "print(f\"Class weights tensor moved to device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ppAflW2gzTjA"
      },
      "outputs": [],
      "source": [
        "# from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# # Compute class weights and store in a dict\n",
        "# class_weights = compute_class_weight('balanced', classes=np.unique(dataset['train']['label']), y=dataset['train']['label'])\n",
        "# class_weights = {class_id: weight for class_id, weight in zip(np.unique(dataset['train']['label']), class_weights)}\n",
        "# print(f\"Computed class weights: {class_weights}\")\n",
        "# # Convert weights to Tensor\n",
        "# class_weight_tensor = torch.tensor(list(class_weights.values()), dtype=torch.float32).to(device)\n",
        "# print(f\"Class weights tensor moved to device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMiyPO_BBPL7"
      },
      "source": [
        "### 1.2.4 Dataset to Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vP_9WQXHHna8"
      },
      "outputs": [],
      "source": [
        "# from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "MAX_LENGTH = 160000  # Use the longest sequence length in your dataset\n",
        "\n",
        "def collate_fn(batch):\n",
        "    inputs = []\n",
        "    for item in batch:\n",
        "        input_values = item['audio'].clone().detach()\n",
        "\n",
        "        # running the line below didn't work properly, I had to manually pad\n",
        "        # padded_inputs = pad_sequence(inputs, batch_first=True).unsqueeze(1)\n",
        "\n",
        "        if len(input_values) < MAX_LENGTH: # pad\n",
        "            padded = torch.cat((input_values, torch.zeros(MAX_LENGTH - len(input_values))))\n",
        "        else: # truncate\n",
        "            padded = input_values[:MAX_LENGTH]\n",
        "        inputs.append(padded)\n",
        "    labels = torch.tensor([item['label'] for item in batch])\n",
        "    return torch.stack(inputs).unsqueeze(1), labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "zJakTgTJDGIz"
      },
      "outputs": [],
      "source": [
        "# convert dataset col to tensors\n",
        "dataset['train'].set_format(type='torch', columns=['audio', 'label'])\n",
        "dataset['test'].set_format(type='torch', columns=['audio', 'label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLpS3Q3FBCuW"
      },
      "source": [
        "# 2. Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56BJjHb9Ueat"
      },
      "source": [
        "## 2.1 Initiate CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "CmWTm254hZjX"
      },
      "outputs": [],
      "source": [
        "class AudioCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(AudioCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool1d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 40000, 256)  # input size should be 160000, which is confirmed wile the model was trained\n",
        "        self.bn_fc1 = nn.BatchNorm1d(256) # batchnorm didn't really work\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        # debug step:\n",
        "        # print(\"Shape after conv1:\", x.shape)\n",
        "\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        # print(\"Shape after conv2:\", x.shape)\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        #print(\"Shape after flattening:\", x.shape)\n",
        "\n",
        "        # x = self.dropout(self.relu(self.fc1(x)))\n",
        "        x = self.dropout(self.relu(self.bn_fc1(self.fc1(x))))\n",
        "        # print(\"Shape after fc1:\", x.shape)\n",
        "\n",
        "        x = self.fc2(x)  # Second fully connected layer (output)\n",
        "        # print(\"Shape after fc2:\", x.shape)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvodsA0S3NJW",
        "outputId": "90008f16-442d-4cb7-891f-0f205cab2b58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AudioCNN(\n",
            "  (conv1): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "  (conv2): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=2560000, out_features=256, bias=True)\n",
            "  (bn_fc1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc2): Linear(in_features=256, out_features=50, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "cnn = AudioCNN(num_classes).to(device)\n",
        "print(cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS6J2RmSUizU"
      },
      "source": [
        "## 2.2 Load Loss, Optimizer and Performance Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "SJfLJPyp1Vxa"
      },
      "outputs": [],
      "source": [
        "loss_fct = nn.CrossEntropyLoss(weight=class_weight_tensor)\n",
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=1e-5, weight_decay=1e-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PJfkxQ_hT3-B"
      },
      "outputs": [],
      "source": [
        "# load performace metric: accuracy\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpzrNpTaBXV2"
      },
      "source": [
        "## 2.3 Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "pq86LJ7YJ5PM"
      },
      "outputs": [],
      "source": [
        "# directory for model saving\n",
        "current_time = datetime.now().strftime(\"%m-%d_%H-%M-%S\")\n",
        "save_dir = f\"checkpoints_{current_time}\"\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfxxHXxt-tJ1",
        "outputId": "66ccaae3-7a23-4745-8342-18d0f22c2f6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [689/1378], Train loss: 3.2199, Train accuracy: 0.2500\n",
            "Test Loss: 7.7746, Test Accuracy: 0.0195\n",
            "Epoch [1/5], Step [1378/1378], Train loss: 3.9224, Train accuracy: 0.0714\n",
            "Test Loss: 3.9106, Test Accuracy: 0.0179\n",
            "Model saved to checkpoints_11-26_15-49-06/model_epoch_1.pth\n",
            "Epoch [2/5], Step [689/1378], Train loss: 3.0229, Train accuracy: 0.4375\n",
            "Test Loss: 4.0102, Test Accuracy: 0.1059\n",
            "Epoch [2/5], Step [1378/1378], Train loss: 3.9216, Train accuracy: 0.0714\n",
            "Test Loss: 3.9090, Test Accuracy: 0.0179\n",
            "Model saved to checkpoints_11-26_15-49-06/model_epoch_2.pth\n",
            "Epoch [3/5], Step [689/1378], Train loss: 2.8098, Train accuracy: 0.4375\n",
            "Test Loss: 3.9594, Test Accuracy: 0.0812\n",
            "Epoch [3/5], Step [1378/1378], Train loss: 3.9208, Train accuracy: 0.0000\n",
            "Test Loss: 3.9074, Test Accuracy: 0.0511\n",
            "Model saved to checkpoints_11-26_15-49-06/model_epoch_3.pth\n",
            "Epoch [4/5], Step [689/1378], Train loss: 2.6070, Train accuracy: 0.4375\n",
            "Test Loss: 4.7324, Test Accuracy: 0.0674\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "# load data\n",
        "train_loader = torch.utils.data.DataLoader(dataset['train'], batch_size=batch_size, collate_fn=collate_fn)\n",
        "test_loader = torch.utils.data.DataLoader(dataset['test'], batch_size=batch_size, collate_fn=collate_fn)\n",
        "\n",
        "# init metric containers\n",
        "train_iter, train_losses, train_accs = [], [], []\n",
        "test_iter, test_losses, test_accs = [], [], []\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "# train and evaluate\n",
        "for epoch in range(num_epochs):\n",
        "  cnn.train()\n",
        "  step = 0\n",
        "  for inputs, labels in train_loader:\n",
        "    step += 1\n",
        "\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    # print(f\"Shape of inputs before passing to model: {inputs.shape}\")\n",
        "    # print(f\"Unique values in labels: {torch.unique(labels)}\")\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = cnn(inputs)\n",
        "\n",
        "    loss = loss_fct(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 689 == 0:\n",
        "      train_iter.append(step + epoch*len(train_loader))\n",
        "      train_losses.append(loss.item())\n",
        "      train_acc = accuracy.compute(predictions=outputs.argmax(axis=1), references=labels)['accuracy']\n",
        "      train_accs.append(train_acc)\n",
        "      print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{step}/{len(train_loader)}], Train loss: {loss.item():.4f}, Train accuracy: {train_acc:.4f}\")\n",
        "\n",
        "      # calculate, append and display evaluation reports\n",
        "      cnn.eval()\n",
        "      test_loss, test_acc = 0, 0\n",
        "      with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          labels = torch.clamp(labels, 0, num_classes - 1).long()\n",
        "          outputs = cnn(inputs)\n",
        "          test_loss += loss_fct(outputs, labels).item()\n",
        "          test_acc += accuracy.compute(predictions=outputs.argmax(axis=1), references=labels)['accuracy']\n",
        "\n",
        "        # append to reports\n",
        "        test_iter.append(step + epoch*len(train_loader))\n",
        "        test_losses.append(test_loss / len(test_loader))\n",
        "        test_accs.append(test_acc / len(test_loader))\n",
        "\n",
        "        # display reports\n",
        "        print(f\"Test Loss: {test_loss / len(test_loader):.4f}, Test Accuracy: {test_acc / len(test_loader):.4f}\")\n",
        "\n",
        "  # schedule lr\n",
        "  scheduler.step()\n",
        "\n",
        "  # Save the model checkpoint at the end of each epoch\n",
        "  checkpoint_path = os.path.join(save_dir, f\"model_epoch_{epoch+1}.pth\")\n",
        "  torch.save({\n",
        "    'epoch': epoch + 1,\n",
        "    'model_state_dict': cnn.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': loss.item(),\n",
        "  }, checkpoint_path)\n",
        "  print(f\"Model saved to {checkpoint_path}\")\n",
        "\n",
        "print('')\n",
        "print(f'Final training loss: {str(train_losses[-1])} accuracy: {str(train_accs[-1])}')\n",
        "print(f'Final validation loss: {str(test_losses[-1])} accuracy: {str(test_accs[-1])}')\n",
        "\n",
        "# Save the final model - with datetime_id\n",
        "\n",
        "\n",
        "final_model_path =  os.path.join(save_dir, f\"/final_model.pth\")\n",
        "torch.save(cnn.state_dict(), final_model_path)\n",
        "print(f\"Final model saved to {final_model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1S05zA7KKbD"
      },
      "outputs": [],
      "source": [
        "# code for resuming\n",
        "# checkpoint = torch.load(\"checkpoints/model_epoch_X.pth\")  # Replace X with the desired epoch\n",
        "# cnn.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# start_epoch = checkpoint['epoch']\n",
        "# loss = checkpoint['loss']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZWJ8m58Ustz"
      },
      "source": [
        "## 2.4 Plot Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gxUjacRGJP5"
      },
      "outputs": [],
      "source": [
        "train_iter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLgWsRcrQEQC"
      },
      "outputs": [],
      "source": [
        "# plots of final loss and accuracy of training and validation data\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_iter, train_losses, label='Train Loss')\n",
        "plt.plot(test_iter, test_losses, label='Validation Loss')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_iter, train_accs, label='Train Accuracy')\n",
        "plt.plot(test_iter, test_accs, label='Validation Accuracy')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.suptitle('Training and Validation Loss and Accuracy')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR9znOQSkZAv"
      },
      "source": [
        "**Notes:**\n",
        "\n",
        "_with_ feature extractor:\n",
        "- **lr=3e-5, weight_decay=0.01:** Final training loss: 3.722187042236328 accuracy: 0.125\n",
        "Final validation loss: 3.581272809536426 accuracy: 0.13271103896103897\n",
        "\n",
        "_without_ feature extractor:\n",
        "- **lr=3e-5, weight_decay=0.01:** Final training loss: 3.9091145992279053 accuracy: 0.0625\n",
        "Final validation loss: 3.9065329734381145 accuracy: 0.05113636363636364\n",
        "- **lr=3e-4, weight_decay=1e-4:** Final training loss: 3.8578035831451416 accuracy: 0.0625\n",
        "Final validation loss: 3.8629037931367947 accuracy: 0.05113636363636364\n",
        "- **10 epochs:** Epoch [1/10], Step [1000/1378], Train loss: 3.8586, Train accuracy: 0.0000\n",
        "Test Loss: 3.8736, Test Accuracy: 0.0511\n",
        "Model saved to checkpoints_11-25_14-39-54/model_epoch_1.pth\n",
        "Epoch [2/10], Step [1000/1378], Train loss: 3.7815, Train accuracy: 0.0000\n",
        "Test Loss: 3.8309, Test Accuracy: 0.0511\n",
        "Model saved to checkpoints_11-25_14-39-54/model_epoch_2.pth\n",
        "Epoch [3/10], Step [1000/1378], Train loss: 3.7240, Train accuracy: 0.0000\n",
        "Test Loss: 3.8027, Test Accuracy: 0.0511\n",
        "Model saved to checkpoints_11-25_14-39-54/model_epoch_3.pth\n",
        "Epoch [4/10], Step [1000/1378], Train loss: 3.6817, Train accuracy: 0.0000\n",
        "Test Loss: 3.7847, Test Accuracy: 0.0511\n",
        "Model saved to checkpoints_11-25_14-39-54/model_epoch_4.pth\n",
        "Epoch [5/10], Step [1000/1378], Train loss: 3.6327, Train accuracy: 0.0625\n",
        "Test Loss: 3.7637, Test Accuracy: 0.0548\n",
        "Model saved to checkpoints_11-25_14-39-54/model_epoch_5.pth\n",
        "Epoch [6/10], Step [1000/1378], Train loss: 3.1374, Train accuracy: 0.1875\n",
        "Test Loss: 3.4809, Test Accuracy: 0.1343\n",
        "Model saved to checkpoints_11-25_14-39-54/model_epoch_6.pth\n",
        "Epoch [7/10], Step [1000/1378], Train loss: 2.5359, Train accuracy: 0.3125\n",
        "Test Loss: 3.1597, Test Accuracy: 0.1928\n",
        "Model saved to checkpoints_11-25_14-39-54/model_epoch_7.pth\n",
        "Epoch [8/10], Step [1000/1378], Train loss: 1.9593, Train accuracy: 0.3750\n",
        "Test Loss: 2.8891, Test Accuracy: 0.2646\n",
        "Model saved to checkpoints_11-25_14-39-54/model_epoch_8.pth\n",
        "Epoch [9/10], Step [1000/1378], Train loss: 1.4299, Train accuracy: 0.5625\n",
        "Test Loss: 2.5677, Test Accuracy: 0.3758\n",
        "Model saved to checkpoints_11-25_14-39-54/model_epoch_9.pth\n",
        "Epoch [10/10], Step [1000/1378], Train loss: 0.8334, Train accuracy: 0.8125\n",
        "Test Loss: 2.3671, Test Accuracy: 0.4614\n",
        "Model saved to checkpoints_11-25_14-39-54/model_epoch_10.pth\n",
        "\n",
        "Final training loss: 0.8333953619003296 accuracy: 0.8125\n",
        "Final validation loss: 2.3671497780007202 accuracy: 0.4614448051948052\n",
        "Final model saved to /final_model.pth\n",
        "\n",
        "- try batch normalisation: Final training loss: 1.1365776062011719 accuracy: 0.875\n",
        "Final validation loss: 27.289619705893777 accuracy: 0.037337662337662336\n",
        "- **added dropout:** Epoch [1/1], Step [500/1378], Train loss: 3.0752, Train accuracy: 0.3125\n",
        "Test Loss: 12.0622, Test Accuracy: 0.0605\n",
        "Epoch [1/1], Step [1000/1378], Train loss: 3.8823, Train accuracy: 0.1875\n",
        "Test Loss: 3.8838, Test Accuracy: 0.0463\n",
        "Model saved to checkpoints_11-26_07-26-57/model_epoch_1.pth\n",
        "\n",
        "Final training loss: 3.8823254108428955 accuracy: 0.1875\n",
        "Final validation loss: 3.883833321658048 accuracy: 0.04626623376623377\n",
        "- **lr=3e-4, weight_decay=1e-2:** Epoch [1/1], Step [500/1378], Train loss: 2.9467, Train accuracy: 0.3750\n",
        "Test Loss: 7.2108, Test Accuracy: 0.0743\n",
        "Epoch [1/1], Step [1000/1378], Train loss: 3.6674, Train accuracy: 0.0625\n",
        "Test Loss: 3.7200, Test Accuracy: 0.1002\n",
        "Model saved to checkpoints_11-26_07-40-09/model_epoch_1.pth\n",
        "\n",
        "Final training loss: 3.6674227714538574 accuracy: 0.0625\n",
        "Final validation loss: 3.7200061129285142 accuracy: 0.1002435064935065\n",
        "Final model saved to /final_model.pth\n",
        "- **lr=3e-4, weight_decay=1e-1:** Epoch [1/1], Step [689/1378], Train loss: 3.2267, Train accuracy: 0.1250\n",
        "Test Loss: 39.7332, Test Accuracy: 0.0373\n",
        "Epoch [1/1], Step [1378/1378], Train loss: 3.8267, Train accuracy: 0.0714\n",
        "Test Loss: 3.8422, Test Accuracy: 0.0548\n",
        "Model saved to checkpoints_11-26_07-51-10/model_epoch_1.pth\n",
        "\n",
        "Final training loss: 3.826742172241211 accuracy: 0.07142857142857142\n",
        "Final validation loss: 3.84219745382086 accuracy: 0.05478896103896104\n",
        "Final model saved to /final_model.pth\n",
        "- let's remove batchnorm and keep dropout and readjust weight decay: Epoch [1/1], Step [689/1378], Train loss: 3.8826, Train accuracy: 0.0000\n",
        "Test Loss: 3.8835, Test Accuracy: 0.0511\n",
        "- batchnorm seems to change the outcomes a lot but results in overfitting\n",
        "- **no batchnorm, dropout, lr=3e-4, weight_decay=1e-3:** Epoch [1/20], Step [689/1378], Train loss: 3.8826, Train accuracy: 0.0000\n",
        "Test Loss: 3.8835, Test Accuracy: 0.0511\n",
        "Epoch [1/20], Step [1378/1378], Train loss: 3.8967, Train accuracy: 0.0000\n",
        "Test Loss: 3.8584, Test Accuracy: 0.0511\n",
        "Model saved to checkpoints_11-26_09-39-21/model_epoch_1.pth\n",
        "Epoch [2/20], Step [689/1378], Train loss: 3.8157, Train accuracy: 0.0000\n",
        "Test Loss: 3.8381, Test Accuracy: 0.0511\n",
        "Epoch [2/20], Step [1378/1378], Train loss: 3.8821, Train accuracy: 0.0000\n",
        "Test Loss: 3.8210, Test Accuracy: 0.0511\n",
        "Model saved to checkpoints_11-26_09-39-21/model_epoch_2.pth\n",
        "Epoch [3/20], Step [689/1378], Train loss: 3.7665, Train accuracy: 0.0000\n",
        "Test Loss: 3.8079, Test Accuracy: 0.0511\n",
        "Epoch [3/20], Step [1378/1378], Train loss: 3.8764, Train accuracy: 0.0000\n",
        "Test Loss: 3.7971, Test Accuracy: 0.0511\n",
        "Model saved to checkpoints_11-26_09-39-21/model_epoch_3.pth\n",
        "Epoch [4/20], Step [689/1378], Train loss: 3.7312, Train accuracy: 0.2500\n",
        "Test Loss: 3.7888, Test Accuracy: 0.0548\n",
        "Epoch [4/20], Step [1378/1378], Train loss: 3.8628, Train accuracy: 0.0714\n",
        "Test Loss: 3.7621, Test Accuracy: 0.0548\n",
        "Model saved to checkpoints_11-26_09-39-21/model_epoch_4.pth\n",
        "Epoch [5/20], Step [689/1378], Train loss: 3.6156, Train accuracy: 0.2500\n",
        "Test Loss: 3.7550, Test Accuracy: 0.0548\n",
        "Epoch [5/20], Step [1378/1378], Train loss: 3.5863, Train accuracy: 0.0714\n",
        "Test Loss: 3.6156, Test Accuracy: 0.0946\n",
        "Model saved to checkpoints_11-26_09-39-21/model_epoch_5.pth\n",
        "Epoch [6/20], Step [689/1378], Train loss: 3.4459, Train accuracy: 0.2500\n",
        "Test Loss: 3.5688, Test Accuracy: 0.0974\n",
        "Epoch [6/20], Step [1378/1378], Train loss: 3.5571, Train accuracy: 0.1429\n",
        "Test Loss: 3.4508, Test Accuracy: 0.1197\n",
        "Model saved to checkpoints_11-26_09-39-21/model_epoch_6.pth\n",
        "Epoch [7/20], Step [689/1378], Train loss: 2.9947, Train accuracy: 0.2500\n",
        "Test Loss: 3.4292, Test Accuracy: 0.1250\n",
        "Epoch [7/20], Step [1378/1378], Train loss: 3.4386, Train accuracy: 0.0714\n",
        "Test Loss: 3.2594, Test Accuracy: 0.1729\n",
        "Model saved to checkpoints_11-26_09-39-21/model_epoch_7.pth\n",
        "Epoch [8/20], Step [689/1378], Train loss: 3.0706, Train accuracy: 0.3125\n",
        "Test Loss: 3.2220, Test Accuracy: 0.1907\n",
        "Epoch [8/20], Step [1378/1378], Train loss: 3.3021, Train accuracy: 0.2143\n",
        "Test Loss: 3.0698, Test Accuracy: 0.2009\n",
        "Model saved to checkpoints_11-26_09-39-21/model_epoch_8.pth\n",
        "Epoch [9/20], Step [689/1378], Train loss: 2.8142, Train accuracy: 0.3125\n",
        "Test Loss: 3.1078, Test Accuracy: 0.1887\n",
        "Epoch [9/20], Step [1378/1378], Train loss: 3.1340, Train accuracy: 0.2143\n",
        "Test Loss: 2.8002, Test Accuracy: 0.2731\n",
        "Model saved to checkpoints_11-26_09-39-21/model_epoch_9.pth\n",
        "Epoch [10/20], Step [689/1378], Train loss: 3.1712, Train accuracy: 0.1250\n",
        "Test Loss: 2.8940, Test Accuracy: 0.2419\n",
        "Epoch [10/20], Step [1378/1378], Train loss: 2.6017, Train accuracy: 0.3571\n",
        "Test Loss: 2.5704, Test Accuracy: 0.3588\n",
        "- still training slowly\n",
        "- ok but I would argue batchnorm makes sense, but the model is not learning properly\n",
        "- Epoch [1/5], Step [689/1378], Train loss: 2.6843, Train accuracy: 0.3750\n",
        "Test Loss: 6.7486, Test Accuracy: 0.0690\n",
        "Epoch [1/5], Step [1378/1378], Train loss: 3.6963, Train accuracy: 0.0714\n",
        "Test Loss: 3.4846, Test Accuracy: 0.1396\n",
        "Model saved to checkpoints_11-26_15-12-49/model_epoch_1.pth\n",
        "Epoch [2/5], Step [689/1378], Train loss: 2.6720, Train accuracy: 0.2500\n",
        "Test Loss: 4.5244, Test Accuracy: 0.1230\n",
        "Epoch [2/5], Step [1378/1378], Train loss: 3.9239, Train accuracy: 0.0714\n",
        "Test Loss: 3.5141, Test Accuracy: 0.1242\n",
        "Model saved to checkpoints_11-26_15-12-49/model_epoch_2.pth\n",
        "Epoch [3/5], Step [689/1378], Train loss: 2.1852, Train accuracy: 0.5000\n",
        "Test Loss: 3.4297, Test Accuracy: 0.2078\n",
        "Epoch [3/5], Step [1378/1378], Train loss: 3.8191, Train accuracy: 0.0000\n",
        "Test Loss: 3.6756, Test Accuracy: 0.0917\n",
        "Model saved to checkpoints_11-26_15-12-49/model_epoch_3.pth\n",
        "- increase learning rate\n",
        "- add a layer\n",
        "- more epochs\n",
        "- ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VTAXQ8Racft"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}