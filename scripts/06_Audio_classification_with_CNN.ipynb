{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreisMarco/02456_G128_bird_classification/blob/main/scripts/06_Audio_classification_with_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWFh3ZDd2xfs"
      },
      "source": [
        "- check: https://towardsdatascience.com/cnns-for-audio-classification-6244954665ab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9f-FLXXbpSd"
      },
      "source": [
        "# 1. Set up environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LAJw6egX4rhI"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYDdhe_hbtkN"
      },
      "source": [
        "## 1.1 Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8a0qjOlnb-wL"
      },
      "outputs": [],
      "source": [
        "# setting up Drive and path for data loading and saving\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# for data processing\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import AutoFeatureExtractor\n",
        "\n",
        "# for model training and evaluation\n",
        "import torch\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# for visualisation\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0W60ydnPzyuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cfb25d2-5bc2-4d13-c347-c4e044a4859f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIjtS5eHbv2_"
      },
      "source": [
        "## 1.2 Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HxnBNBYLhCcz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c17d19f-0c94-416e-9c51-e053449abc78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount Drive and set path\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Deep Learning - DTU 2024/'\n",
        "os.chdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rlmgqFc1fNwM"
      },
      "outputs": [],
      "source": [
        "# load (one batch of) preprocessed data\n",
        "batch_path = 'batch_1'\n",
        "dataset = Dataset.load_from_disk(batch_path).remove_columns('__index_level_0__')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujUq-Thh08fG",
        "outputId": "f9de997e-c1dc-4ba7-dba7-a352e00057b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['audio', 'label'],\n",
              "    num_rows: 1244\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# inspect structure\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QMGn4r7zCo8F"
      },
      "outputs": [],
      "source": [
        "# takes a minute\n",
        "# df = pd.DataFrame(dataset)\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WdTxGAbpAUH2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "443fc963-532c-49e9-82e8-b66c5b547da3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes in the dataset: 4\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(set(dataset[\"label\"]))\n",
        "print(f\"Number of classes in the dataset: {num_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVtW2mpyAcBW"
      },
      "source": [
        "### 1.2.x Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guAsdpSUyoOX",
        "outputId": "cbb3a74d-38b1-46a6-cde8-5c1c0ccff7ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_dir = 'facebook/wav2vec2-base-960h'\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja3d46_rvDvL",
        "outputId": "cee3822a-3b13-4d5f-fd40-e67f342ca404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed dataset with feature extractor.\n"
          ]
        }
      ],
      "source": [
        "# pad data\n",
        "def preprocess_function(example):\n",
        "    inputs = feature_extractor(example['audio'], sampling_rate=16000, padding=True)\n",
        "    return inputs\n",
        "dataset = dataset.map(preprocess_function, remove_columns=\"audio\", batched=True, batch_size=32)\n",
        "print(\"Preprocessed dataset with feature extractor.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljR-90TiAtDh"
      },
      "source": [
        "### 1.2.x Split Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "U3BfD0nTufmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d48ca28-3848-46a3-9de8-18dbbbeaaf40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split dataset into training and testing.\n"
          ]
        }
      ],
      "source": [
        "# split dataset into train, val and test\n",
        "dataset = dataset.train_test_split(test_size=0.1, shuffle=True, stratify_by_column=\"label\", seed=42)\n",
        "print(\"Split dataset into training and testing.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY6LLRisAz86"
      },
      "source": [
        "### 1.2.x Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ppAflW2gzTjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71dbe651-fd23-4003-eabb-34331a69ce34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed class weights: {19: 1.5985714285714285, 40: 0.8797169811320755, 47: 1.8048387096774194, 49: 0.5939490445859873}\n",
            "Class weights tensor moved to device: cuda\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Compute class weights and store in a dict\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(dataset['train']['label']), y=dataset['train']['label'])\n",
        "class_weights = {class_id: weight for class_id, weight in zip(np.unique(dataset['train']['label']), class_weights)}\n",
        "print(f\"Computed class weights: {class_weights}\")\n",
        "# Convert weights to Tensor\n",
        "class_weight_tensor = torch.tensor(list(class_weights.values()), dtype=torch.float32).to(device)\n",
        "print(f\"Class weights tensor moved to device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z62Cf5TA9uP"
      },
      "source": [
        "### 1.2.x Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "R-7sDzNGzuuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "261e4283-90f9-445e-c65e-caaa6579540b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded evaluation metric: accuracy.\n"
          ]
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "# Use accuracy as performace metric\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "print(\"Loaded evaluation metric: accuracy.\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    # Extract the model's predictions from eval_pred.\n",
        "    predictions = eval_pred.predictions\n",
        "    # Apply the softmax function to convert prediction scores into probabilities.\n",
        "    predictions = np.exp(predictions) / np.exp(predictions).sum(axis=1, keepdims=True)\n",
        "    # Extract the true label IDs from eval_pred.\n",
        "    label_ids = eval_pred.label_ids\n",
        "    # Calculate accuracy using the loaded accuracy metric by comparing predicted classes\n",
        "    # (argmax of probabilities) with the true label IDs.\n",
        "    acc_score = accuracy.compute(predictions=predictions.argmax(axis=1), references=label_ids)['accuracy']\n",
        "    # Return the computed accuracy as a dictionary with a key \"accuracy.\"\n",
        "    return {\n",
        "        \"accuracy\": acc_score\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMiyPO_BBPL7"
      },
      "source": [
        "### 1.2.x Dataset to Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "XQvircD4-voO"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Custom collate function for padding\n",
        "def collate_fn(batch):\n",
        "    inputs = [torch.tensor(item['input_values']) for item in batch]\n",
        "    labels = [item['label'] for item in batch]\n",
        "    # Pad inputs to the same length\n",
        "    padded_inputs = pad_sequence(inputs, batch_first=True)\n",
        "    return padded_inputs, torch.tensor(labels)\n",
        "\n",
        "# Update DataLoader to use the custom collate function\n",
        "train_loader = torch.utils.data.DataLoader(dataset['train'], batch_size=16, collate_fn=collate_fn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zJakTgTJDGIz"
      },
      "outputs": [],
      "source": [
        "# convert dataset col to tensors\n",
        "dataset['train'].set_format(type='torch', columns=['input_values', 'label'])\n",
        "dataset['test'].set_format(type='torch', columns=['input_values', 'label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vBhPmWWzDHEz"
      },
      "outputs": [],
      "source": [
        "# load data into trainloader\n",
        "train_loader = torch.utils.data.DataLoader(dataset['train'], batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = torch.utils.data.DataLoader(dataset['test'], batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "aGpkOMLEFgJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b5ae7dc-22f8-49e5-82e4-e6d7e246b693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-2.0947, -1.5041,  1.7549,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.2565, -2.1944, -1.9779,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.3438,  0.5573,  0.4359,  ...,  0.0024,  0.0024,  0.0024],\n",
            "        ...,\n",
            "        [-0.5987, -0.1466, -0.5357,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0799,  0.2995, -0.3648,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.1942,  0.0842,  0.5323,  ...,  0.0000,  0.0000,  0.0000]]), tensor([40, 40, 40, 49, 49, 49, 40, 47, 40, 49, 19, 40, 49, 49, 47, 19, 19, 49,\n",
            "        49, 19, 49, 40, 40, 40, 49, 19, 19, 49, 49, 47, 49, 49]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-ec4126985197>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  inputs = [torch.tensor(item['input_values']) for item in batch]\n"
          ]
        }
      ],
      "source": [
        "# inspecting data format\n",
        "for batch in train_loader:\n",
        "    print(batch)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GldgvUtlmaED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "849741b7-4b89-4421-aebc-e384096288ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([58050])\n"
          ]
        }
      ],
      "source": [
        "sample = dataset['train']['input_values'][0]  # Get the first sample\n",
        "print(sample.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLpS3Q3FBCuW"
      },
      "source": [
        "### 1.2.x Intitiating CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9BuT6G40oxhR"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CmWTm254hZjX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class AudioCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(AudioCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool1d(2, 2)\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 40000, 256)  # input size should be 160000, which is confirmed wile the model was trained\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))  # First convolution and pooling\n",
        "        print(\"Shape after conv1:\", x.shape)  # Print the shape after conv1\n",
        "        x = self.pool(self.relu(self.conv2(x)))  # Second convolution and pooling\n",
        "        print(\"Shape after conv2:\", x.shape)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        print(\"Shape after flattening:\", x.shape)\n",
        "        x = self.relu(self.fc1(x))  # First fully connected layer\n",
        "        print(\"Shape after fc1:\", x.shape)\n",
        "        # x = self.dropout(x)\n",
        "        # print(\"Shape after dropout:\", x.shape)\n",
        "        x = self.fc2(x)  # Second fully connected layer (output)\n",
        "        print(\"Shape after fc2:\", x.shape)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cL5L5id6b2hH"
      },
      "outputs": [],
      "source": [
        "# # adapted from CIFAR exercise\n",
        "# class CNN_audio(nn.Module):\n",
        "#     def __init__(self, num_classes):\n",
        "#         super().__init__()\n",
        "#         self.num_classes = num_classes\n",
        "#         # Three convolutional layers\n",
        "#         self.conv1 = nn.Conv1d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "#         self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "#         self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "#         # Fully connected layers\n",
        "#         self.fc1 = nn.Linear(4 * 4 * 64, 256)  # Input size calculated dynamically in forward method\n",
        "#         self.fc2 = nn.Linear(256, 128)\n",
        "#         self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "#         # Batch Normalization after each layer for Optimization\n",
        "#         self.bn1 = nn.BatchNorm1d(16)\n",
        "#         self.bn2 = nn.BatchNorm1d(32)\n",
        "#         self.bn3 = nn.BatchNorm1d(64)\n",
        "\n",
        "#         # Pooling\n",
        "#         self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "\n",
        "#         # Activation\n",
        "#         self.relu = nn.ReLU() # delete if you prefere F.relu in the forward part below\n",
        "\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Your code here!\n",
        "\n",
        "#         # without batch normalization\n",
        "#         # x = self.pool(self.relu(self.conv1(x)))  # 32x32 -> 16x16\n",
        "#         # x = self.pool(self.relu(self.conv2(x)))  # 16x16 -> 8x8\n",
        "#         # x = self.pool(self.relu(self.conv3(x)))  # 8x8 -> 4x4\n",
        "\n",
        "#         # with batch normalization\n",
        "#         x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
        "#         print(x.shape)\n",
        "#         x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
        "#         print(x.shape)\n",
        "#         x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
        "#         print(x.shape)\n",
        "\n",
        "\n",
        "#         x = x.view(x.size(0), -1)  # Flatten all dimensions except batch\n",
        "#         x = self.relu(self.fc1(x))  # if you get an error regarding this relu, specify it above as: self.relu1 = nn.ReLU() and so forth.\n",
        "#         x = self.relu(self.fc2(x))\n",
        "#         x = self.fc3(x)\n",
        "#         return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2KuQ3-indCiR"
      },
      "outputs": [],
      "source": [
        "# n_classes = n_classes\n",
        "\n",
        "# model = CNN_audio(n_classes)\n",
        "# device = torch.device('cuda')  # use cuda or cpu\n",
        "# model.to(device)\n",
        "# print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pvodsA0S3NJW"
      },
      "outputs": [],
      "source": [
        "model = AudioCNN(num_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "SJfLJPyp1Vxa"
      },
      "outputs": [],
      "source": [
        "loss_fct = nn.CrossEntropyLoss(weight=class_weight_tensor)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpzrNpTaBXV2"
      },
      "source": [
        "### 1.2.x Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xPRm-COt2dUl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "0d673c2a-c9b1-4c16-dbec-956b42a6c78f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-ec4126985197>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  inputs = [torch.tensor(item['input_values']) for item in batch]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-8c3fd8bb8fa7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Add the channel dimension for Conv1d: [batch_size, 1, sequence_length]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Add the channel dimension for Conv1d: [batch_size, 1, sequence_length]\n",
        "        inputs = inputs.unsqueeze(1)  # Shape: [batch_size, 1, sequence_length]\n",
        "\n",
        "        print(f\"Shape of inputs before passing to model: {inputs.shape}\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        print(f\"Unique values in labels: {torch.unique(labels)}\")\n",
        "\n",
        "        loss = loss_fct(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0V8PshkCEGa"
      },
      "source": [
        "### 1.2.x Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "5-tenOFV2sYa",
        "outputId": "f600eb76-a2c8-4290-8cdc-c7e1cec39161"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "each element in list of batch should be of equal size",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-58fb5a2caf6d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 clone.update(\n\u001b[0;32m--> 171\u001b[0;31m                     {\n\u001b[0m\u001b[1;32m    172\u001b[0m                         key: collate(\n\u001b[1;32m    173\u001b[0m                             \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 clone.update(\n\u001b[1;32m    171\u001b[0m                     {\n\u001b[0;32m--> 172\u001b[0;31m                         key: collate(\n\u001b[0m\u001b[1;32m    173\u001b[0m                             \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0melem_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"each element in list of batch should be of equal size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# It may be accessed twice, so we use a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "accuracy = correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0yzdVQWbyjU"
      },
      "source": [
        "# 2. Explore & preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEeAyxAVoEo0"
      },
      "outputs": [],
      "source": [
        "# from CIFAR exercise\n",
        "from sklearn import metrics\n",
        "\n",
        "def accuracy(target, pred):\n",
        "    return metrics.accuracy_score(target.detach().cpu().numpy(), pred.detach().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc32ashF5vT4",
        "outputId": "6c3c934f-986a-4d01-c1a8-51dcec6a1df2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['inputs', 'targets'],\n",
              "    num_rows: 746\n",
              "})"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "gOUREpC-dKjq",
        "outputId": "c54f8643-7582-4946-92cf-edb104297a81"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "stack expects each tensor to be equal size, but got [58050] at entry 0 and [53334] at entry 14",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-64d78bf24b08>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# for inputs, targets in train_loader:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#     inputs, targets = inputs.to(device), targets.to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Iterate over the dataloader directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Access inputs and move to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Access targets and move to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mclone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 clone.update(\n\u001b[0;32m--> 171\u001b[0;31m                     {\n\u001b[0m\u001b[1;32m    172\u001b[0m                         key: collate(\n\u001b[1;32m    173\u001b[0m                             \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 clone.update(\n\u001b[1;32m    171\u001b[0m                     {\n\u001b[0;32m--> 172\u001b[0;31m                         key: collate(\n\u001b[0m\u001b[1;32m    173\u001b[0m                             \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [58050] at entry 0 and [53334] at entry 14"
          ]
        }
      ],
      "source": [
        "# train model - from CIFAR exercise\n",
        "\n",
        "num_epochs = 1\n",
        "validation_every_steps = 500\n",
        "\n",
        "step = 0\n",
        "model.train()\n",
        "\n",
        "train_iter = []\n",
        "valid_iter = []\n",
        "train_accuracies = []\n",
        "valid_accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    train_accuracies_batches = []\n",
        "\n",
        "    # for inputs, targets in train_loader:\n",
        "    #     inputs, targets = inputs.to(device), targets.to(device)\n",
        "    for batch in train_loader: # Iterate over the dataloader directly\n",
        "        inputs = batch['inputs'].to(device)  # Access inputs and move to device\n",
        "        targets = batch['targets'].to(device)  # Access targets and move to device\n",
        "\n",
        "\n",
        "        # Your code here!\n",
        "        optimizer.zero_grad()             # resets gradients\n",
        "        # train and forward pass\n",
        "        output = model(inputs)\n",
        "\n",
        "        # compute gradients given loss (backpropagation)\n",
        "        loss = loss_fn(output, targets)   # computing the cross entropy loss\n",
        "        loss.backward()                   # computing gradients based on the loss\n",
        "        optimizer.step()                  # parameter update using the computed gradients\n",
        "\n",
        "        # Increment step counter\n",
        "        step += 1\n",
        "\n",
        "        # Compute accuracy.\n",
        "        predictions = output.max(1)[1]                                    # get predicted class\n",
        "        train_accuracies_batches.append(accuracy(targets, predictions))   # calculate and store training batch accuracy\n",
        "\n",
        "        if step % validation_every_steps == 0:\n",
        "\n",
        "            # Append average training accuracy to list.\n",
        "            train_iter.append(step)\n",
        "            train_accuracies.append(np.mean(train_accuracies_batches))\n",
        "\n",
        "            train_accuracies_batches = []\n",
        "\n",
        "            # Compute accuracies on validation set.\n",
        "            valid_accuracies_batches = []\n",
        "            with torch.no_grad():\n",
        "                model.eval()\n",
        "                for inputs, targets in test_loader:\n",
        "                    inputs, targets = inputs.to(device), targets.to(device)\n",
        "                    output = model(inputs)\n",
        "                    loss = loss_fn(output, targets)\n",
        "\n",
        "                    predictions = output.max(1)[1]\n",
        "\n",
        "                    # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).\n",
        "                    valid_accuracies_batches.append(accuracy(targets, predictions) * len(inputs))\n",
        "\n",
        "                model.train()\n",
        "\n",
        "            # Append average validation accuracy to list.\n",
        "            valid_iter.append(step)\n",
        "            valid_accuracies.append(np.sum(valid_accuracies_batches) / len(test_set))\n",
        "\n",
        "            print(f\"Step {step:<5}   training accuracy: {train_accuracies[-1]}\")\n",
        "            print(f\"             test accuracy: {valid_accuracies[-1]}\")\n",
        "\n",
        "print(\"Finished training.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCRvacMQnFW6"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(12,4))\n",
        "plt.plot(train_iter, train_accuracies, label='train_accs')\n",
        "plt.plot(valid_iter, valid_accuracies, label='valid_accs')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_ZoMxn1b27h"
      },
      "source": [
        "# 4. Evaluate CNN and display results\n",
        "- from https://github.com/sn1218/Audio-Classification/blob/main/Classification_of_Audio_Data_using_Machine_Learning.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvmkM3KAb5bu"
      },
      "outputs": [],
      "source": [
        "# prepare testing set\n",
        "test_path = 'Data/genres_test'\n",
        "X_test, y_test = prepare_features(test_path)\n",
        "\n",
        "\n",
        "print(y_test)\n",
        "print(\"Features shape:\", X_test.shape)\n",
        "print(\"Number of labels:\", len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvQSI6mYdr8P"
      },
      "outputs": [],
      "source": [
        "# encode genres using same labelEncoder as above\n",
        "y_test_encoded = le.transform(y_test)\n",
        "y_test_categorical = to_categorical(y_test_encoded, num_classes=len(le.classes_))\n",
        "\n",
        "\n",
        "# print accuracy of test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_categorical)\n",
        "print(f'Test accuracy: {test_accuracy:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGnP5sImdcTs"
      },
      "outputs": [],
      "source": [
        "# make confusion matrix\n",
        "\n",
        "# make predictions on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test_categorical, axis=1)\n",
        "\n",
        "# genre labels\n",
        "genre_labels = ['blues', 'country', 'hiphop', 'jazz', 'disco', 'pop', 'classical', 'reggae', 'rock', 'metal']\n",
        "\n",
        "# compute confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=genre_labels)\n",
        "\n",
        "# plot confusion matrix\n",
        "cm_display.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Genres')\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('True Genres')\n",
        "plt.show()\n",
        "\n",
        "# generate classification report\n",
        "report = classification_report(y_true, y_pred_classes, target_names=genre_labels)\n",
        "\n",
        "print(\"Classification Report:\\n\")\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}